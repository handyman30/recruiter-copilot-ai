# RecruiterCopilot.ai Deployment Guide

## Quick Deployment Options

### Option 1: Railway (Recommended - Easiest)
Railway provides one-click deployment with automatic SSL and database provisioning.

1. **Fork the repository** to your GitHub account
2. **Sign up at [Railway.app](https://railway.app)** (free tier available)
3. **Click "New Project" â†’ "Deploy from GitHub repo"**
4. **Add environment variables:**
   ```
   DATABASE_URL=<auto-generated by Railway>
   GEMINI_API_KEY=AIzaSyCAxol5vL_Z_yZebOH45-O0bWPj4XCxQOY
   USE_GEMINI=true
   ```
5. **Deploy!** Railway will automatically:
   - Build and deploy your app
   - Provision a PostgreSQL database
   - Generate a public URL (yourapp.railway.app)

### Option 2: Vercel + Supabase
Great for frontend performance and free database hosting.

1. **Backend API on Vercel:**
   - Push code to GitHub
   - Import to Vercel
   - Set environment variables
   - Deploy server folder as API routes

2. **Database on Supabase:**
   - Create free Supabase project
   - Get connection string
   - Run Prisma migrations

### Option 3: Render.com
All-in-one platform with free tier.

1. Create a new Web Service
2. Connect GitHub repo
3. Set build command: `cd server && npm install && npm run build`
4. Set start command: `cd server && npm start`
5. Add PostgreSQL database
6. Add environment variables

## Production Checklist

- [ ] Set NODE_ENV=production
- [ ] Enable CORS for your domain only
- [ ] Set up error monitoring (Sentry)
- [ ] Configure rate limiting
- [ ] Set up backups for PostgreSQL
- [ ] Use environment variables for all secrets
- [ ] Enable SSL/HTTPS (automatic on most platforms)

## Scaling Considerations

1. **AI API Limits:**
   - Gemini Free: 1,500 requests/min
   - Consider upgrading for production use
   - Implement caching for repeated analyses

2. **File Storage:**
   - Current: Files stored in database (OK for MVP)
   - Future: Use S3 or Cloudinary for scalability

3. **Performance:**
   - Add Redis for caching
   - Use CDN for static assets
   - Implement job queues for heavy processing 